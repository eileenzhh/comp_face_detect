{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:51:05.809193Z","iopub.status.busy":"2022-12-12T10:51:05.808881Z","iopub.status.idle":"2022-12-12T10:51:06.141085Z","shell.execute_reply":"2022-12-12T10:51:06.140504Z","shell.execute_reply.started":"2022-12-12T10:51:05.809155Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from bs4 import BeautifulSoup\n","import torchvision\n","from torchvision import transforms, datasets, models\n","import torch\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","import matplotlib.patches as patches\n","import xml\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:51:06.142464Z","iopub.status.busy":"2022-12-12T10:51:06.142246Z","iopub.status.idle":"2022-12-12T10:51:09.783119Z","shell.execute_reply":"2022-12-12T10:51:09.782192Z","shell.execute_reply.started":"2022-12-12T10:51:06.142437Z"},"trusted":true},"outputs":[],"source":["def generate_box(obj):\n","    \n","    xmin = int(obj.find('xmin').text)\n","    ymin = int(obj.find('ymin').text)\n","    xmax = int(obj.find('xmax').text)\n","    ymax = int(obj.find('ymax').text)\n","    \n","    return [xmin, ymin, xmax, ymax]\n","\n","def generate_label(obj):\n","    if obj.find('name').text == \"with_mask\":\n","        return 1\n","    elif obj.find('name').text == \"mask_weared_incorrect\":\n","        return 2\n","    return 0\n","\n","def generate_target(image_id, file): \n","    with open(file) as f:\n","        data = f.read()\n","        soup = BeautifulSoup(data, 'xml')\n","        objects = soup.find_all('object')\n","\n","        num_objs = len(objects)\n","\n","        # Bounding boxes for objects\n","        # In coco format, bbox = [xmin, ymin, width, height]\n","        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n","        boxes = []\n","        labels = []\n","        for i in objects:\n","            boxes.append(generate_box(i))\n","            labels.append(generate_label(i))\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","        # Labels (In my case, I only one class: target class or background)\n","        labels = torch.as_tensor(labels, dtype=torch.int64)\n","        # Tensorise img_id\n","        img_id = torch.tensor([image_id])\n","        # Annotation is in dictionary format\n","        target = {}\n","        target[\"boxes\"] = boxes\n","        target[\"labels\"] = labels\n","        target[\"image_id\"] = img_id\n","        \n","        return target"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:51:10.062033Z","iopub.status.busy":"2022-12-12T10:51:10.061868Z","iopub.status.idle":"2022-12-12T10:51:11.911775Z","shell.execute_reply":"2022-12-12T10:51:11.911Z","shell.execute_reply.started":"2022-12-12T10:51:10.06201Z"},"trusted":true},"outputs":[],"source":["imgs = list(sorted(os.listdir(\"kaggle/input/face-mask-detection/images/\")))\n","labels = list(sorted(os.listdir(\"kaggle/input/face-mask-detection/annotations/\")))\n","# input\\face-mask-detection\\images"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T10:51:11.913026Z","iopub.status.busy":"2022-12-12T10:51:11.91283Z","iopub.status.idle":"2022-12-12T10:51:11.918049Z","shell.execute_reply":"2022-12-12T10:51:11.916566Z","shell.execute_reply.started":"2022-12-12T10:51:11.913002Z"},"trusted":true},"outputs":[],"source":["class MaskDataset(object):\n","    def __init__(self, transforms):\n","        self.transforms = transforms\n","        # load all image files, sorting them to\n","        # ensure that they are aligned\n","        self.imgs = list(sorted(os.listdir(\"kaggle/input/face-mask-detection/images/\")))\n","        # self.labels = list(sorted(os.listdir(\"/kaggle/input/face-mask-detection/annotations/\")))\n","\n","    def __getitem__(self, idx):\n","        # load images ad masks\n","        file_image = 'maksssksksss'+ str(idx) + '.png'\n","        file_label = 'maksssksksss'+ str(idx) + '.xml'\n","        img_path = os.path.join(\"kaggle/input/face-mask-detection/images/\", file_image)\n","        label_path = os.path.join(\"kaggle/input/face-mask-detection/annotations/\", file_label)\n","        img = Image.open(img_path).convert(\"RGB\")\n","        #Generate Label\n","        target = generate_target(idx, label_path)\n","        \n","        if self.transforms is not None:\n","            img = self.transforms(img)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.imgs)"]},{"cell_type":"code","execution_count":53,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:51:11.921313Z","iopub.status.busy":"2022-12-12T10:51:11.921052Z","iopub.status.idle":"2022-12-12T10:52:24.651452Z","shell.execute_reply":"2022-12-12T10:52:24.650571Z","shell.execute_reply.started":"2022-12-12T10:51:11.921281Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of dataset is 853 \n","Length of training set is : 597 \n","Length of test set is : 256\n"]}],"source":["data_transform = transforms.Compose([\n","        transforms.ToTensor(), \n","    ])\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","dataset = MaskDataset(data_transform)\n","\n","train_size=int(len(dataset)*0.7)\n","test_size=len(dataset)-train_size\n","print('Length of dataset is', len(dataset), '\\nLength of training set is :',train_size,'\\nLength of test set is :', test_size)\n","\n","trainset, testset = torch.utils.data.random_split(dataset,[train_size,test_size])\n","train_dataloader = torch.utils.data.DataLoader(dataset=trainset,batch_size=4,shuffle=True,collate_fn=collate_fn)\n","test_dataloader = torch.utils.data.DataLoader(dataset=testset,batch_size=4,shuffle=True,collate_fn=collate_fn)\n","# data_loader = torch.utils.data.DataLoader(\n","#  dataset, batch_size=4, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:52:24.733512Z","iopub.status.busy":"2022-12-12T10:52:24.733302Z","iopub.status.idle":"2022-12-12T10:52:24.741933Z","shell.execute_reply":"2022-12-12T10:52:24.741163Z","shell.execute_reply.started":"2022-12-12T10:52:24.733485Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n","                               else \"cpu\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from torch import nn\n","from collections import OrderedDict\n","from torch.nn import functional as F"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def gabor_kernel(frequency,  sigma_x, sigma_y, theta=0, offset=0, ks=61):\n","\n","    w = ks // 2\n","    grid_val = torch.arange(-w, w+1, dtype=torch.float)\n","    x, y = torch.meshgrid(grid_val, grid_val)\n","    rotx = x * np.cos(theta) + y * np.sin(theta)\n","    roty = -x * np.sin(theta) + y * np.cos(theta)\n","    g = torch.zeros(y.shape)\n","    g[:] = torch.exp(-0.5 * (rotx ** 2 / sigma_x ** 2 + roty ** 2 / sigma_y ** 2))\n","    g /= 2 * np.pi * sigma_x * sigma_y\n","    g *= torch.cos(2 * np.pi * frequency * rotx + offset)\n","\n","    return g\n","\n","\n","def sample_dist(hist, bins, ns, scale='linear'):\n","    rand_sample = np.random.rand(ns)\n","    if scale == 'linear':\n","        rand_sample = np.interp(rand_sample, np.hstack(([0], hist.cumsum())), bins)\n","    elif scale == 'log2':\n","        rand_sample = np.interp(rand_sample, np.hstack(([0], hist.cumsum())), np.log2(bins))\n","        rand_sample = 2**rand_sample\n","    elif scale == 'log10':\n","        rand_sample = np.interp(rand_sample, np.hstack(([0], hist.cumsum())), np.log10(bins))\n","        rand_sample = 10**rand_sample\n","    return rand_sample\n"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["class Identity(nn.Module):\n","    def forward(self, x):\n","        return x\n","\n","\n","class GFB(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=4):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = (kernel_size, kernel_size)\n","        self.stride = (stride, stride)\n","        self.padding = (kernel_size // 2, kernel_size // 2)\n","        self.conv1 = nn.Conv2d(in_channels=64, out_channels=512, kernel_size=3, padding=1)\n","\n","        # Param instatiations\n","        self.weight = torch.zeros((out_channels, in_channels, kernel_size, kernel_size))\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        return F.conv2d(x, self.weight, None, self.stride, self.padding)\n","\n","    def initialize(self, sf, theta, sigx, sigy, phase):\n","        random_channel = torch.randint(0, self.in_channels, (self.out_channels,))\n","        for i in range(self.out_channels):\n","            self.weight[i, random_channel[i]] = gabor_kernel(frequency=sf[i], sigma_x=sigx[i], sigma_y=sigy[i],\n","                                                             theta=theta[i], offset=phase[i], ks=self.kernel_size[0])\n","        self.weight = nn.Parameter(self.weight, requires_grad=False)\n","\n","\n","class VOneBlock(nn.Module):\n","    def __init__(self, sf, theta, sigx, sigy, phase,\n","                 k_exc=25, noise_mode=None, noise_scale=1, noise_level=1,\n","                 simple_channels=128, complex_channels=128, ksize=25, stride=4, input_size=224):\n","        super().__init__()\n","\n","        self.in_channels = 3\n","\n","        self.simple_channels = simple_channels\n","        self.complex_channels = complex_channels\n","        self.out_channels = simple_channels + complex_channels\n","        self.stride = stride\n","        self.input_size = input_size\n","\n","        self.sf = sf\n","        self.theta = theta\n","        self.sigx = sigx\n","        self.sigy = sigy\n","        self.phase = phase\n","        self.k_exc = k_exc\n","\n","        self.set_noise_mode(noise_mode, noise_scale, noise_level)\n","        self.fixed_noise = None\n","\n","        self.simple_conv_q0 = GFB(self.in_channels, self.out_channels, ksize, stride)\n","        self.simple_conv_q1 = GFB(self.in_channels, self.out_channels, ksize, stride)\n","        self.simple_conv_q0.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n","                                       phase=self.phase)\n","        self.simple_conv_q1.initialize(sf=self.sf, theta=self.theta, sigx=self.sigx, sigy=self.sigy,\n","                                       phase=self.phase + np.pi / 2)\n","\n","        self.simple = nn.ReLU(inplace=True)\n","        self.complex = Identity()\n","        self.gabors = Identity()\n","        self.noise = nn.ReLU(inplace=True)\n","        self.output = Identity()\n","\n","    def forward(self, x):\n","        # Gabor activations [Batch, out_channels, H/stride, W/stride]\n","        x = self.gabors_f(x)\n","        # Noise [Batch, out_channels, H/stride, W/stride]\n","        x = self.noise_f(x)\n","        # V1 Block output: (Batch, out_channels, H/stride, W/stride)\n","        x = self.output(x)\n","        return x\n","\n","    def gabors_f(self, x):\n","        s_q0 = self.simple_conv_q0(x)\n","        s_q1 = self.simple_conv_q1(x)\n","        c = self.complex(torch.sqrt(s_q0[:, self.simple_channels:, :, :] ** 2 +\n","                                    s_q1[:, self.simple_channels:, :, :] ** 2 + 1e-8) / np.sqrt(2))\n","        s = self.simple(s_q0[:, 0:self.simple_channels, :, :])\n","        return self.gabors(self.k_exc * torch.cat((s, c), 1))\n","\n","    def noise_f(self, x):\n","        if self.noise_mode == 'neuronal':\n","            eps = 10e-5\n","            x *= self.noise_scale\n","            x += self.noise_level\n","            if self.fixed_noise is not None:\n","                x += self.fixed_noise * torch.sqrt(F.relu(x.clone()) + eps)\n","            else:\n","                x += torch.distributions.normal.Normal(torch.zeros_like(x), scale=1).rsample() * \\\n","                     torch.sqrt(F.relu(x.clone()) + eps)\n","            x -= self.noise_level\n","            x /= self.noise_scale\n","        if self.noise_mode == 'gaussian':\n","            if self.fixed_noise is not None:\n","                x += self.fixed_noise * self.noise_scale\n","            else:\n","                x += torch.distributions.normal.Normal(torch.zeros_like(x), scale=1).rsample() * self.noise_scale\n","        return self.noise(x)\n","\n","    def set_noise_mode(self, noise_mode=None, noise_scale=1, noise_level=1):\n","        self.noise_mode = noise_mode\n","        self.noise_scale = noise_scale\n","        self.noise_level = noise_level\n","\n","    def fix_noise(self, batch_size=256, seed=None):\n","        noise_mean = torch.zeros(batch_size, self.out_channels, int(self.input_size/self.stride),\n","                                 int(self.input_size/self.stride))\n","        if seed:\n","            torch.manual_seed(seed)\n","        if self.noise_mode:\n","            self.fixed_noise = torch.distributions.normal.Normal(noise_mean, scale=1).rsample().to(device)\n","\n","    def unfix_noise(self):\n","        self.fixed_noise = None\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# ResNet Back-End architecture\n","# Based on Torchvision implementation in\n","# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    __constants__ = ['downsample']\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True) #\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    __constants__ = ['downsample']\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True) # inplace=True\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNetBackEnd(nn.Module):\n","    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n","                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None):\n","        super(ResNetBackEnd, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                       dilate=replace_stride_with_dilation[2])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, previous_dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _forward_impl(self, x):\n","        # See note [TorchScript super()]\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","    def forward(self, x):\n","        return self._forward_impl(x)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import scipy.stats as stats\n","\n","\n","def generate_gabor_param(features, seed=0, rand_flag=False, sf_corr=0, sf_max=9, sf_min=0):\n","    # Generates random sample\n","    np.random.seed(seed)\n","\n","    phase_bins = np.array([0, 360])\n","    phase_dist = np.array([1])\n","\n","    if rand_flag:\n","        print('Uniform gabor parameters')\n","        ori_bins = np.array([0, 180])\n","        ori_dist = np.array([1])\n","\n","        nx_bins = np.array([0.1, 10**0.2])\n","        nx_dist = np.array([1])\n","\n","        ny_bins = np.array([0.1, 10**0.2])\n","        ny_dist = np.array([1])\n","\n","        # sf_bins = np.array([0.5, 8])\n","        # sf_dist = np.array([1])\n","\n","        sf_bins = np.array([0.5, 0.7, 1.0, 1.4, 2.0, 2.8, 4.0, 5.6, 8])\n","        sf_dist = np.array([1,  1,  1, 1, 1, 1, 1, 1])\n","\n","        sfmax_ind = np.where(sf_bins < sf_max)[0][-1]\n","        sfmin_ind = np.where(sf_bins >= sf_min)[0][0]\n","\n","        sf_bins = sf_bins[sfmin_ind:sfmax_ind+1]\n","        sf_dist = sf_dist[sfmin_ind:sfmax_ind]\n","\n","        sf_dist = sf_dist / sf_dist.sum()\n","    else:\n","        print('Neuronal distributions gabor parameters')\n","        # DeValois 1982a\n","        ori_bins = np.array([-22.5, 22.5, 67.5, 112.5, 157.5])\n","        ori_dist = np.array([66, 49, 77, 54])\n","        ori_dist = ori_dist / ori_dist.sum()\n","\n","        # Schiller 1976\n","        cov_mat = np.array([[1, sf_corr], [sf_corr, 1]])\n","\n","        # Ringach 2002b\n","        nx_bins = np.logspace(-1, 0.2, 6, base=10)\n","        ny_bins = np.logspace(-1, 0.2, 6, base=10)\n","        n_joint_dist = np.array([[2.,  0.,  1.,  0.,  0.],\n","                                 [8.,  9.,  4.,  1.,  0.],\n","                                 [1.,  2., 19., 17.,  3.],\n","                                 [0.,  0.,  1.,  7.,  4.],\n","                                 [0.,  0.,  0.,  0.,  0.]])\n","        n_joint_dist = n_joint_dist / n_joint_dist.sum()\n","        nx_dist = n_joint_dist.sum(axis=1)\n","        nx_dist = nx_dist / nx_dist.sum()\n","        ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n","\n","        # DeValois 1982b\n","        sf_bins = np.array([0.5, 0.7, 1.0, 1.4, 2.0, 2.8, 4.0, 5.6, 8])\n","        sf_dist = np.array([4,  4,  8, 25, 32, 26, 28, 12])\n","\n","        sfmax_ind = np.where(sf_bins <= sf_max)[0][-1]\n","        sfmin_ind = np.where(sf_bins >= sf_min)[0][0]\n","\n","        sf_bins = sf_bins[sfmin_ind:sfmax_ind+1]\n","        sf_dist = sf_dist[sfmin_ind:sfmax_ind]\n","\n","        sf_dist = sf_dist / sf_dist.sum()\n","\n","    phase = sample_dist(phase_dist, phase_bins, features)\n","    ori = sample_dist(ori_dist, ori_bins, features)\n","    ori[ori < 0] = ori[ori < 0] + 180\n","\n","    if rand_flag:\n","        sf = sample_dist(sf_dist, sf_bins, features, scale='log2')\n","        nx = sample_dist(nx_dist, nx_bins, features, scale='log10')\n","        ny = sample_dist(ny_dist, ny_bins, features, scale='log10')\n","    else:\n","\n","        samps = np.random.multivariate_normal([0, 0], cov_mat, features)\n","        samps_cdf = stats.norm.cdf(samps)\n","\n","        nx = np.interp(samps_cdf[:,0], np.hstack(([0], nx_dist.cumsum())), np.log10(nx_bins))\n","        nx = 10**nx\n","\n","        ny_samp = np.random.rand(features)\n","        ny = np.zeros(features)\n","        for samp_ind, nx_samp in enumerate(nx):\n","            bin_id = np.argwhere(nx_bins < nx_samp)[-1]\n","            ny[samp_ind] = np.interp(ny_samp[samp_ind], np.hstack(([0], ny_dist_marg[bin_id, :].cumsum())),\n","                                             np.log10(ny_bins))\n","        ny = 10**ny\n","\n","        sf = np.interp(samps_cdf[:,1], np.hstack(([0], sf_dist.cumsum())), np.log2(sf_bins))\n","        sf = 2**sf\n","\n","    return sf, ori, phase, nx, ny\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["def VOneNet(sf_corr=0.75, sf_max=9, sf_min=0, rand_param=False, gabor_seed=0,\n","            simple_channels=256, complex_channels=256,\n","            noise_mode='neuronal', noise_scale=0.35, noise_level=0.07, k_exc=25,\n","            model_arch='resnet50', image_size=224, visual_degrees=8, ksize=25, stride=4):\n","\n","\n","    out_channels = simple_channels + complex_channels\n","\n","    sf, theta, phase, nx, ny = generate_gabor_param(out_channels, gabor_seed, rand_param, sf_corr, sf_max, sf_min)\n","\n","    gabor_params = {'simple_channels': simple_channels, 'complex_channels': complex_channels, 'rand_param': rand_param,\n","                    'gabor_seed': gabor_seed, 'sf_max': sf_max, 'sf_corr': sf_corr, 'sf': sf.copy(),\n","                    'theta': theta.copy(), 'phase': phase.copy(), 'nx': nx.copy(), 'ny': ny.copy()}\n","    arch_params = {'k_exc': k_exc, 'arch': model_arch, 'ksize': ksize, 'stride': stride}\n","\n","\n","    # Conversions\n","    ppd = image_size / visual_degrees\n","    sf = sf / ppd\n","    sigx = nx / sf\n","    sigy = ny / sf\n","    theta = theta/180 * np.pi\n","    phase = phase / 180 * np.pi\n","\n","    vone_block = VOneBlock(sf=sf, theta=theta, sigx=sigx, sigy=sigy, phase=phase,\n","                           k_exc=k_exc, noise_mode=noise_mode, noise_scale=noise_scale, noise_level=noise_level,\n","                           simple_channels=simple_channels, complex_channels=complex_channels,\n","                           ksize=ksize, stride=stride, input_size=image_size)\n","\n","    if model_arch:\n","        bottleneck = nn.Conv2d(out_channels, 64, kernel_size=1, stride=1, bias=False)\n","        nn.init.kaiming_normal_(bottleneck.weight, mode='fan_out', nonlinearity='relu')\n","        # model_back_end = ResNetBackEnd(block=Bottleneck, layers=[3, 4, 6, 3])\n","        model_back_end = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","        # get number of input features for the classifier\n","        in_features = model_back_end.roi_heads.box_predictor.cls_score.in_features\n","        # replace the pre-trained head with a new one\n","        model_back_end.roi_heads.box_predictor = FastRCNNPredictor(in_features, 3)\n","        model_back_end.backbone.body.layer1 = vone_block\n","        model = model_back_end\n","        # model = nn.Sequential(OrderedDict([\n","        #     ('transform', vone_block),\n","        #     ('bottleneck', bottleneck),\n","        #     ('model', model_back_end),\n","        # ]))\n","    else:\n","        print('Model: ', 'VOneNet')\n","        model = vone_block\n","\n","    model.image_size = image_size\n","    model.visual_degrees = visual_degrees\n","    model.gabor_params = gabor_params\n","    model.arch_params = arch_params\n","\n","    return model\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["import requests\n","from torch.nn import Module\n","\n","FILE_WEIGHTS = {'alexnet': 'vonealexnet_e70.pth.tar', 'resnet50': 'voneresnet50_e70.pth.tar',\n","                'resnet50_at': 'voneresnet50_at_e96.pth.tar', 'cornets': 'vonecornets_e70.pth.tar',\n","                'resnet50_ns': 'voneresnet50_ns_e70.pth.tar'}\n","\n","\n","class Wrapper(Module):\n","    def __init__(self, model):\n","        super(Wrapper, self).__init__()\n","        self.module = model\n","\n","\n","def get_model(model_arch='resnet50', pretrained=True, map_location='cpu', **kwargs):\n","    \"\"\"\n","    Returns a VOneNet model.\n","    Select pretrained=True for returning one of the 3 pretrained models.\n","    model_arch: string with identifier to choose the architecture of the back-end (resnet50, cornets, alexnet)\n","    \"\"\"\n","    if pretrained and model_arch:\n","        url = f'https://vonenet-models.s3.us-east-2.amazonaws.com/{FILE_WEIGHTS[model_arch.lower()]}'\n","        home_folder = os.path.expanduser('~')\n","        vonenet_dir = os.path.join('vonenet/')\n","        weightsdir_path = os.path.join(vonenet_dir, FILE_WEIGHTS[model_arch.lower()])\n","        print(weightsdir_path)\n","        if not os.path.exists(vonenet_dir):\n","            os.makedirs(vonenet_dir)\n","        if not os.path.exists(weightsdir_path):\n","            print('Downloading model weights to ', weightsdir_path)\n","            r = requests.get(url, allow_redirects=True)\n","            open(weightsdir_path, 'wb').write(r.content)\n","\n","        ckpt_data = torch.load(weightsdir_path, map_location=map_location)\n","\n","        stride = ckpt_data['flags']['stride']\n","        simple_channels = ckpt_data['flags']['simple_channels']\n","        complex_channels = ckpt_data['flags']['complex_channels']\n","        k_exc = ckpt_data['flags']['k_exc']\n","\n","        noise_mode = ckpt_data['flags']['noise_mode']\n","        noise_scale = ckpt_data['flags']['noise_scale']\n","        noise_level = ckpt_data['flags']['noise_level']\n","\n","        model_id = ckpt_data['flags']['arch'].replace('_','').lower()\n","\n","        model = globals()[f'VOneNet'](model_arch=model_id, stride=stride, k_exc=k_exc,\n","                                      simple_channels=simple_channels, complex_channels=complex_channels,\n","                                      noise_mode=noise_mode, noise_scale=noise_scale, noise_level=noise_level)\n","\n","        if model_arch.lower() == 'resnet50_at':\n","            ckpt_data['state_dict'].pop('vone_block.div_u.weight')\n","            ckpt_data['state_dict'].pop('vone_block.div_t.weight')\n","            model.load_state_dict(ckpt_data['state_dict'])\n","        else:\n","            model = Wrapper(model)\n","            model.load_state_dict(ckpt_data['state_dict'])\n","            model = model.module\n","\n","        model = nn.DataParallel(model)\n","    else:\n","        model = globals()[f'VOneNet'](model_arch=model_arch, **kwargs)\n","        model = nn.DataParallel(model)\n","\n","    model.to(map_location)\n","    return model\n","\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Neuronal distributions gabor parameters\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Eileen\\AppData\\Local\\Temp\\ipykernel_2780\\2262397701.py:56: RuntimeWarning: invalid value encountered in divide\n","  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n","C:\\Users\\Eileen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","C:\\Users\\Eileen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["import os.path\n","model = get_model(pretrained=False, map_location=None)\n","\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":38,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:52:26.330194Z","iopub.status.busy":"2022-12-12T10:52:26.329492Z","iopub.status.idle":"2022-12-12T10:52:26.336777Z","shell.execute_reply":"2022-12-12T10:52:26.335854Z","shell.execute_reply.started":"2022-12-12T10:52:26.330156Z"},"trusted":true},"outputs":[],"source":["for param in model.parameters():\n","    param.requires_grad=False"]},{"cell_type":"code","execution_count":73,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:52:26.337982Z","iopub.status.busy":"2022-12-12T10:52:26.337773Z","iopub.status.idle":"2022-12-12T10:52:26.350109Z","shell.execute_reply":"2022-12-12T10:52:26.349681Z","shell.execute_reply.started":"2022-12-12T10:52:26.337954Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DataParallel(\n","  (module): FasterRCNN(\n","    (transform): GeneralizedRCNNTransform(\n","        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","    )\n","    (backbone): BackboneWithFPN(\n","      (body): IntermediateLayerGetter(\n","        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","        (relu): ReLU(inplace=True)\n","        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","        (layer1): VOneBlock(\n","          (simple_conv_q0): GFB(\n","            (conv1): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (simple_conv_q1): GFB(\n","            (conv1): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (simple): ReLU(inplace=True)\n","          (complex): Identity()\n","          (gabors): Identity()\n","          (noise): ReLU(inplace=True)\n","          (output): Identity()\n","        )\n","        (layer2): Sequential(\n","          (0): Bottleneck(\n","            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","            (downsample): Sequential(\n","              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","              (1): FrozenBatchNorm2d(512, eps=0.0)\n","            )\n","          )\n","          (1): Bottleneck(\n","            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (2): Bottleneck(\n","            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (3): Bottleneck(\n","            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","        )\n","        (layer3): Sequential(\n","          (0): Bottleneck(\n","            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","            (downsample): Sequential(\n","              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","              (1): FrozenBatchNorm2d(1024, eps=0.0)\n","            )\n","          )\n","          (1): Bottleneck(\n","            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (2): Bottleneck(\n","            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (3): Bottleneck(\n","            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (4): Bottleneck(\n","            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (5): Bottleneck(\n","            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","        )\n","        (layer4): Sequential(\n","          (0): Bottleneck(\n","            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","            (downsample): Sequential(\n","              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","              (1): FrozenBatchNorm2d(2048, eps=0.0)\n","            )\n","          )\n","          (1): Bottleneck(\n","            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (2): Bottleneck(\n","            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","            (relu): ReLU(inplace=True)\n","          )\n","        )\n","      )\n","      (fpn): FeaturePyramidNetwork(\n","        (inner_blocks): ModuleList(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","        )\n","        (layer_blocks): ModuleList(\n","          (0-3): 4 x Conv2dNormActivation(\n","            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","        )\n","        (extra_blocks): LastLevelMaxPool()\n","      )\n","    )\n","    (rpn): RegionProposalNetwork(\n","      (anchor_generator): AnchorGenerator()\n","      (head): RPNHead(\n","        (conv): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (1): ReLU(inplace=True)\n","          )\n","        )\n","        (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","        (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","    )\n","    (roi_heads): RoIHeads(\n","      (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","      (box_head): TwoMLPHead(\n","        (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","        (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","      )\n","      (box_predictor): FastRCNNPredictor(\n","        (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","        (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n","      )\n","    )\n","  )\n",")"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:52:26.377371Z","iopub.status.busy":"2022-12-12T10:52:26.376696Z","iopub.status.idle":"2022-12-12T10:52:26.385781Z","shell.execute_reply":"2022-12-12T10:52:26.38456Z","shell.execute_reply.started":"2022-12-12T10:52:26.377331Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Number of Parameters for conv2D is : 73728\n"]}],"source":["conv_param = 64 * 128 * 3 * 3\n","print(' Number of Parameters for conv2D is :', conv_param )"]},{"cell_type":"code","execution_count":74,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:52:26.387333Z","iopub.status.busy":"2022-12-12T10:52:26.387051Z","iopub.status.idle":"2022-12-12T10:52:26.395626Z","shell.execute_reply":"2022-12-12T10:52:26.394462Z","shell.execute_reply.started":"2022-12-12T10:52:26.387297Z"},"trusted":true},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion=nn.CrossEntropyLoss()\n","optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)"]},{"cell_type":"code","execution_count":67,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:52:26.397Z","iopub.status.busy":"2022-12-12T10:52:26.396733Z","iopub.status.idle":"2022-12-12T10:52:26.406036Z","shell.execute_reply":"2022-12-12T10:52:26.405455Z","shell.execute_reply.started":"2022-12-12T10:52:26.396965Z"},"trusted":true},"outputs":[],"source":["param.requires_grad=True\n","# ct = 0\n","# for child in model.module.model.children():\n","#     print(child)\n","#     print(\"next\")\n","#     ct += 1\n","#     if ct < 2:\n","#         for param in child.parameters():\n","#             param.requires_grad = False"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","[{'boxes': tensor([[ 15., 111., 114., 219.],\n","        [324., 135., 410., 238.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([165], device='cuda:0')}, {'boxes': tensor([[170.,  43., 195.,  69.],\n","        [ 36.,  99.,  54., 114.],\n","        [234., 153., 258., 186.],\n","        [383., 127., 400., 150.],\n","        [220.,  86., 230., 102.]], device='cuda:0'), 'labels': tensor([1, 0, 0, 0, 0], device='cuda:0'), 'image_id': tensor([575], device='cuda:0')}, {'boxes': tensor([[117., 153., 162., 200.],\n","        [204.,  20., 221.,  41.],\n","        [282.,  17., 307.,  40.],\n","        [243.,  74., 264.,  98.],\n","        [110.,  11., 117.,  19.],\n","        [131.,  14., 138.,  22.],\n","        [166.,   8., 174.,  15.],\n","        [322.,  38., 333.,  47.],\n","        [269.,  10., 278.,  20.],\n","        [233.,   6., 240.,  16.],\n","        [245.,   1., 250.,   7.],\n","        [145.,  21., 154.,  32.],\n","        [141.,  30., 156.,  53.]], device='cuda:0'), 'labels': tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), 'image_id': tensor([723], device='cuda:0')}, {'boxes': tensor([[175.,  89., 196., 120.],\n","        [ 70.,  93.,  81., 104.]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([628], device='cuda:0')}]\n"]}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)\n","for imgs, annotations in train_dataloader:\n","    # imgs = imgs.to(device)\n","    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n","    print(annotations)\n","    break"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"Given groups=1, weight of size [512, 3, 25, 25], expected input[1, 512, 200, 320] to have 3 channels, but got 512 channels instead","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[75], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# imgs = imgs.to(device)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m annotations \u001b[38;5;241m=\u001b[39m [{k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m annotations]\n\u001b[1;32m---> 19\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mvalues())        \n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\parallel\\data_parallel.py:183\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m    185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:101\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     94\u001b[0m             degen_bb: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m boxes[bb_idx]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     95\u001b[0m             torch\u001b[38;5;241m.\u001b[39m_assert(\n\u001b[0;32m     96\u001b[0m                 \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll bounding boxes should have positive height and width.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found invalid box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegen_bb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for target at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m             )\n\u001b[1;32m--> 101\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\detection\\backbone_utils.py:57\u001b[0m, in \u001b[0;36mBackboneWithFPN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[1;32m---> 57\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfpn(x)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:69\u001b[0m, in \u001b[0;36mIntermediateLayerGetter.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers:\n\u001b[0;32m     71\u001b[0m         out_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers[name]\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[70], line 70\u001b[0m, in \u001b[0;36mVOneBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Gabor activations [Batch, out_channels, H/stride, W/stride]\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgabors_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Noise [Batch, out_channels, H/stride, W/stride]\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_f(x)\n","Cell \u001b[1;32mIn[70], line 78\u001b[0m, in \u001b[0;36mVOneBlock.gabors_f\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgabors_f\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 78\u001b[0m     s_q0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_conv_q0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     s_q1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_conv_q1(x)\n\u001b[0;32m     80\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplex(torch\u001b[38;5;241m.\u001b[39msqrt(s_q0[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_channels:, :, :] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     81\u001b[0m                                 s_q1[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_channels:, :, :] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m))\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[70], line 21\u001b[0m, in \u001b[0;36mGFB.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 3, 25, 25], expected input[1, 512, 200, 320] to have 3 channels, but got 512 channels instead"]}],"source":["num_epochs = 10\n","model.to(device)\n","# parameters\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                                momentum=0.9, weight_decay=0.0005)\n","\n","len_dataloader = len(train_dataloader)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    i = 0    \n","    epoch_loss = 0\n","    for imgs, annotations in train_dataloader:\n","        i += 1\n","        imgs = list(img.to(device) for img in imgs)\n","        # imgs = imgs.to(device)\n","        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n","        loss_dict = model([imgs[0]], [annotations[0]])\n","        losses = sum(loss for loss in loss_dict.values())        \n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step() \n","#         print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')\n","        epoch_loss += losses\n","    print(epoch_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-12-12T10:52:26.407973Z","iopub.status.busy":"2022-12-12T10:52:26.407518Z","iopub.status.idle":"2022-12-12T10:55:20.839304Z","shell.execute_reply":"2022-12-12T10:55:20.838305Z","shell.execute_reply.started":"2022-12-12T10:52:26.407935Z"},"trusted":true},"outputs":[{"ename":"TypeError","evalue":"conv2d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[59], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [{k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m labels]\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\parallel\\data_parallel.py:183\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m    185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[9], line 68\u001b[0m, in \u001b[0;36mVOneBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# Gabor activations [Batch, out_channels, H/stride, W/stride]\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgabors_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Noise [Batch, out_channels, H/stride, W/stride]\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_f(x)\n","Cell \u001b[1;32mIn[9], line 76\u001b[0m, in \u001b[0;36mVOneBlock.gabors_f\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgabors_f\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 76\u001b[0m     s_q0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_conv_q0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     s_q1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_conv_q1(x)\n\u001b[0;32m     78\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplex(torch\u001b[38;5;241m.\u001b[39msqrt(s_q0[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_channels:, :, :] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     79\u001b[0m                                 s_q1[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_channels:, :, :] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m))\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[9], line 19\u001b[0m, in \u001b[0;36mGFB.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n"]}],"source":["#n_epochs=1\n","EPOCHS = 10\n","\n","for epoch in range(EPOCHS): \n","    running_loss = 0.0\n","    train_losses = []\n","    for i, (inputs, labels) in enumerate(train_dataloader):\n","        \n","        if torch.cuda.is_available():\n","            # print(\"cuda available\")\n","            # inputs , labels = inputs.cuda(), labels.cuda()\n","            model = model.to(device)\n","            inputs = list(img.to(device) for img in inputs)\n","            labels = [{k: v.to(device) for k, v in t.items()} for t in labels]\n","\n","        optimizer.zero_grad()\n","        \n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item() \n","        if i % 20 == 19:    \n","                \n","                print(\"Epoch {}, batch {}, training loss {}\".format(epoch, i+1,running_loss/20))\n","        \n","        running_loss = 0.0\n","     \n","    \n","\n","print('\\nFinished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 6.5512,  3.6843,  1.8982,  ..., -0.5124,  0.5077, -0.9274],\n","        [ 4.8815,  2.9943, -1.2782,  ..., -0.3285,  4.4941,  0.8487],\n","        [ 5.7674,  1.9499,  0.6117,  ...,  0.9192,  0.5603,  1.1950],\n","        ...,\n","        [ 7.6508,  2.4646,  0.3673,  ..., -0.3463,  3.9141,  0.0813],\n","        [ 7.6473,  1.3844,  0.8201,  ...,  1.1839,  0.9540, -1.9095],\n","        [ 6.5053,  1.3115,  0.2314,  ..., -0.0748,  2.0209,  1.2324]],\n","       device='cuda:0')\n","tensor([ 36, 163,   0, 749,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0, 929,   0,   0, 501,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0,\n","        1, 2, 0, 0, 0, 1, 1, 0], device='cuda:0')\n","tensor([[ 6.0610,  1.7843,  0.4060,  ...,  1.1524,  2.5752,  0.6085],\n","        [ 4.7768,  1.8318,  2.5483,  ..., -1.0037,  2.0188, -1.2496],\n","        [ 7.2238, -0.1695,  1.6984,  ..., -0.3417,  1.3329, -0.7623],\n","        ...,\n","        [ 6.3027,  4.7405,  1.9609,  ...,  0.4664,  2.5675, -0.0764],\n","        [10.1497,  4.9406,  2.5160,  ...,  1.4874,  1.7973, -1.1431],\n","        [ 5.5430,  1.4512,  0.9269,  ..., -0.5748,  1.8511,  2.8736]],\n","       device='cuda:0')\n","tensor([  0, 381,   0,   0,   0,  78,   0, 735,   0, 422,   0,   0,   0, 381,\n","          0,   0,   0, 843,   0,   0,   0, 381,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n","tensor([[ 4.3087e+00,  1.8684e+00, -1.6191e+00,  ..., -5.0843e-01,\n","          2.3848e+00, -4.5940e-01],\n","        [ 2.7922e+00,  2.2237e+00, -1.4720e+00,  ...,  5.9949e-01,\n","          1.9095e+00,  3.1643e+00],\n","        [ 5.8051e+00,  8.7931e-01, -1.0701e-01,  ...,  1.2446e+00,\n","          3.0312e+00, -1.4379e-01],\n","        ...,\n","        [ 6.9992e+00,  3.9639e-01,  1.3206e+00,  ...,  4.1803e+00,\n","          1.6460e+00, -1.2311e-01],\n","        [ 5.4362e+00,  2.0331e+00,  2.0711e-01,  ..., -9.8945e-01,\n","         -1.1105e-01,  1.2212e+00],\n","        [ 6.9556e+00,  2.1627e+00, -6.7483e-03,  ..., -2.2557e-01,\n","          1.7205e+00,  7.2869e-02]], device='cuda:0')\n","tensor([831, 604,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 758,   0,\n","          0, 103,   0,   0,   0,   0, 381,   0,   0,   0,   0, 570,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 4.5565,  3.6979,  0.1866,  ...,  0.9926,  1.2618,  0.1356],\n","        [ 7.8339,  0.7869,  0.3493,  ..., -1.1269,  2.3652,  1.1205],\n","        [ 7.8116,  2.2750, -0.6324,  ...,  0.8110,  4.2004, -0.6193],\n","        ...,\n","        [ 6.5584,  2.3019,  0.4005,  ..., -0.2130,  3.3667, -1.0190],\n","        [ 5.9967,  2.6806,  1.0429,  ..., -0.5336,  2.3263, -0.4208],\n","        [ 6.4270,  2.9751, -0.0150,  ...,  0.8264,  2.4915,  1.1212]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 902,   0,   0,   0,\n","          0, 490,   0,   0,   0,   0, 934,   0,   0, 758,   0,   0,   0, 813,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 7.2523,  2.6079,  1.9131,  ...,  0.4656,  2.9143, -0.3699],\n","        [ 6.0098,  2.8341, -0.7246,  ...,  0.6591,  4.0117,  1.5478],\n","        [ 5.1681,  3.6549, -0.2561,  ...,  1.3543,  2.3533, -1.4048],\n","        ...,\n","        [ 7.0105,  2.3753,  1.7365,  ..., -0.4760,  1.8864,  0.4358],\n","        [ 6.5699,  3.0120,  1.6232,  ...,  0.8539,  0.9938,  0.1633],\n","        [ 7.9993,  1.1929,  1.2386,  ...,  1.1425,  2.4865,  0.3299]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0, 805,   0, 643, 549,   0,   0,   0, 845,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0, 670,   0,   0,   0,   0,\n","          0,   0, 103,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 2,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 8.0142,  2.4856,  0.6720,  ...,  1.9684,  1.2966, -1.2569],\n","        [ 5.9120,  3.7514,  0.1125,  ...,  0.5359,  1.0857,  0.0410],\n","        [ 5.7889,  1.4345, -2.0785,  ..., -0.0152,  1.4928,  0.9584],\n","        ...,\n","        [ 6.0812,  1.5230, -0.0680,  ..., -1.7308,  1.3290, -0.4041],\n","        [ 7.0288,  2.2322,  0.1337,  ..., -0.7337,  2.1031, -2.3967],\n","        [ 6.4976,  2.8991, -0.4404,  ...,  0.8558,  4.6959, -0.7593]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0, 491,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n","        0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 6.9701,  2.5438,  2.4540,  ...,  0.0808,  0.5615, -0.1834],\n","        [ 7.7751,  4.1002,  1.0754,  ...,  0.6208,  4.2631, -0.1173],\n","        [ 7.3746,  1.9839,  0.1627,  ...,  1.3292,  5.0876,  0.3430],\n","        ...,\n","        [ 6.6709,  1.9099,  0.7360,  ...,  1.0409,  2.9350, -0.0883],\n","        [ 6.5779,  2.4729,  0.7466,  ...,  1.3616,  1.9654, -0.7843],\n","        [ 8.1572,  5.3589,  0.3013,  ...,  2.2143,  2.9255,  1.0301]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0, 851,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 792,   0,   0,   0,   0, 439,   0,   0, 711,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","tensor([[ 7.2659e+00,  3.4977e+00,  2.4138e+00,  ..., -2.1179e-03,\n","          2.4713e+00,  5.1773e-01],\n","        [ 5.8334e+00,  2.0052e+00, -9.3799e-01,  ..., -7.1865e-01,\n","          1.4400e+00,  3.1735e-01],\n","        [ 5.5467e+00,  5.5383e-01,  6.5843e-01,  ..., -7.1387e-01,\n","          6.2898e-01, -1.9603e+00],\n","        ...,\n","        [ 5.4254e+00,  3.8662e+00, -9.7114e-01,  ...,  6.4423e-01,\n","          5.0873e+00,  1.9140e+00],\n","        [ 8.1537e+00,  1.3655e+00, -7.2255e-01,  ...,  1.3869e+00,\n","          9.9497e-01,  1.7314e-01],\n","        [ 6.9294e+00,  5.2936e+00,  1.6972e+00,  ...,  5.0168e-01,\n","          1.6345e+00,  7.9791e-01]], device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0, 758,   0,   0,   0,   0,   0,   0, 940,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 672, 876,   0,\n","          0, 567,   0,   0], device='cuda:0')\n","tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","tensor([[ 6.6342,  2.2327, -0.8579,  ...,  0.0607,  1.2286,  0.9445],\n","        [ 5.1248,  1.1040,  1.5083,  ..., -0.8191,  0.6697,  0.1549],\n","        [ 6.6519,  2.4161,  0.1644,  ...,  0.3917, -0.1625,  0.0087],\n","        ...,\n","        [ 6.1897,  2.8263, -0.4629,  ...,  0.5730,  2.2878,  0.5038],\n","        [ 6.5994,  3.2042,  2.4778,  ...,  0.5515,  1.1711, -0.2448],\n","        [ 7.1275,  1.9982, -0.4687,  ...,  2.1438,  2.0128,  0.7180]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0, 633,   0,   0,   0, 744,   0,   0,   0,\n","          0,   0,   0,   0, 758,   0,   0,   0,   0,   0,   0,   0, 666,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n","        1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","tensor([[ 7.4379,  2.5836,  0.6381,  ..., -0.2270,  3.1113, -0.3296],\n","        [ 7.7402,  1.6509, -0.5512,  ..., -1.0673,  3.1424,  1.0512],\n","        [ 5.9368,  3.0445,  1.0716,  ...,  0.8792,  1.3944, -1.1827],\n","        ...,\n","        [ 6.2925,  2.9118, -0.1349,  ...,  1.2134,  4.7740,  0.3637],\n","        [ 9.1258,  3.0585,  1.4405,  ...,  1.2466,  2.5197, -1.2790],\n","        [ 6.7684,  2.0210, -1.5871,  ..., -0.3384,  1.6245, -0.4890]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0, 593,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0, 389,   0,   0,   0, 636,   0,   0,   0, 633,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n","        0, 2, 0, 0, 0, 1, 1, 1], device='cuda:0')\n","tensor([[ 8.8119,  2.4571,  1.2358,  ...,  1.4601,  1.5770, -1.6688],\n","        [ 7.2381,  1.6995,  0.7815,  ...,  0.6295,  1.2095,  1.1146],\n","        [ 8.6200,  4.8099,  0.8514,  ...,  1.9569,  3.0390, -1.5232],\n","        ...,\n","        [ 7.2328,  0.7054, -0.3729,  ..., -0.5600,  3.8272, -0.5941],\n","        [ 7.1795,  1.4845, -0.8215,  ...,  2.0020,  2.1786, -0.6926],\n","        [ 6.0391,  1.0687, -1.4622,  ...,  0.1829,  2.9844,  0.5879]],\n","       device='cuda:0')\n","tensor([  0,   0,   0, 758,   0,   0,   0,   0,   0,   0,   0,   0,   0, 591,\n","          0, 262,   0, 455,   0,   0,   0,   0,   0,   0,   0,   0, 379,   0,\n","          0,   0,   0, 462], device='cuda:0')\n","tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 9.6105,  2.4333,  1.4378,  ...,  2.5159,  2.8574, -0.7024],\n","        [ 9.0963,  4.3901,  1.7604,  ..., -0.5313,  2.5544,  0.2386],\n","        [ 9.2920,  6.0290,  1.2810,  ...,  0.9663,  2.3990, -1.0413],\n","        ...,\n","        [ 7.0590,  1.8633,  1.0113,  ...,  0.8722,  0.8354,  0.7699],\n","        [ 7.5733,  3.0181,  1.7226,  ...,  1.1794,  1.5768,  2.0135],\n","        [ 4.2777,  2.0810, -1.1243,  ...,  0.3473,  2.6320,  1.8261]],\n","       device='cuda:0')\n","tensor([  0,   0,   0, 408, 389, 584, 902, 737,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0, 449,   0,   0, 221,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0, 954], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1,\n","        2, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 8.2178,  3.2395,  1.4263,  ...,  0.2873,  2.0185,  0.2500],\n","        [ 8.1726,  3.5989,  2.4957,  ...,  2.2977,  4.3888, -0.0761],\n","        [ 6.6685,  4.0829, -1.7987,  ...,  1.5261,  7.2800, -0.5898],\n","        ...,\n","        [ 5.2988,  2.1258,  0.9180,  ...,  0.4521,  2.3406,  1.0792],\n","        [ 6.1298,  1.2452, -0.1480,  ..., -1.3389,  1.0016, -1.3441],\n","        [ 5.9243,  2.1150, -0.0579,  ...,  1.1284,  1.3951,  0.5488]],\n","       device='cuda:0')\n","tensor([  0,   0, 473,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 714, 530, 463,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","tensor([[ 4.9759,  3.2657,  1.6656,  ...,  0.6150,  1.8552,  1.5504],\n","        [ 7.7870,  2.4726, -1.3568,  ...,  1.6022,  3.8413, -1.7355],\n","        [ 9.0494,  3.5672,  0.3213,  ...,  1.2834,  2.5856,  0.9288],\n","        ...,\n","        [ 4.2097,  1.9266, -0.0554,  ..., -0.0958,  2.8964,  1.5808],\n","        [ 6.6079,  2.5686, -0.1006,  ...,  0.4801,  1.6285, -0.0759],\n","        [ 6.5324,  1.9023, -0.9194,  ..., -1.0411,  0.7028,  0.2721]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 982,\n","          0, 381,   0, 676], device='cuda:0')\n","tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n","        1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","tensor([[ 5.6850e+00,  3.1730e+00,  7.0608e-01,  ...,  2.2860e-01,\n","          5.5252e-03,  4.4476e-01],\n","        [ 8.1435e+00,  2.8628e+00, -5.1836e-01,  ...,  4.0636e-01,\n","          2.9409e+00, -1.3669e+00],\n","        [ 8.3929e+00,  1.7439e+00,  2.4620e-01,  ...,  5.0484e-01,\n","          1.7743e+00, -1.6396e+00],\n","        ...,\n","        [ 8.0365e+00,  3.9394e+00, -2.5437e-01,  ...,  1.2685e+00,\n","          2.5560e+00, -5.3724e-01],\n","        [ 8.7623e+00,  4.2974e+00,  2.1856e+00,  ...,  1.3446e+00,\n","          5.1561e+00, -1.4143e+00],\n","        [ 4.8817e+00,  2.7354e+00,  1.2562e+00,  ..., -7.1143e-01,\n","          1.2000e-01, -2.6432e-01]], device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 796,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","tensor([[ 5.9888,  1.9864, -0.2865,  ..., -0.1404,  2.5074,  1.0919],\n","        [ 5.8118,  2.9696,  1.9701,  ..., -1.0505,  0.8648, -0.0930],\n","        [ 5.8686,  2.0718,  0.7019,  ...,  0.4133,  2.5220,  0.0787],\n","        ...,\n","        [ 7.4929,  3.2787,  1.6830,  ...,  1.3846,  1.6717,  0.4938],\n","        [ 5.3972,  2.4912, -0.1051,  ..., -1.6355,  1.9998,  4.0078],\n","        [ 5.2074,  0.5089, -0.5920,  ..., -1.1608,  0.5865,  0.6822]],\n","       device='cuda:0')\n","tensor([  0,   0,   0, 796,   0,   0,   0,   0, 568,   0, 778,   0, 929, 836,\n","          0, 239,   0,   0,   0,   0,   0,   0, 929, 758,   0,   0,   0, 391,\n","          0,   0, 399,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 7.6257,  1.6511,  0.7369,  ...,  0.0869,  0.9543,  2.2348],\n","        [ 6.2463,  2.6241,  0.0248,  ..., -0.0256,  1.4620,  0.6417],\n","        [ 6.9845,  4.1379,  2.1447,  ...,  0.7659,  2.6480, -0.4001],\n","        ...,\n","        [ 8.3383,  3.8749,  0.2096,  ...,  1.3630,  2.9285,  0.2997],\n","        [ 5.0006,  4.6895, -2.7148,  ..., -0.0119,  2.8024, -0.3981],\n","        [ 8.6881,  3.2821, -0.0644,  ...,  0.0542,  2.5281,  1.0860]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0, 728,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","tensor([[ 6.0632,  3.3440, -0.2666,  ..., -0.9745,  2.6861,  0.5516],\n","        [ 7.3348,  1.1932,  0.8443,  ...,  2.4903,  0.3525, -0.4881],\n","        [ 6.2800, -0.1155,  4.2856,  ..., -2.4838,  0.2197,  0.6818],\n","        ...,\n","        [ 4.7609,  3.2437,  1.5086,  ..., -0.5649,  1.3045,  1.2774],\n","        [ 3.1490,  4.0597, -1.4217,  ..., -1.2520,  2.2500,  2.4759],\n","        [ 4.8297,  2.3123, -0.2096,  ...,  0.8021,  1.7299,  1.3173]],\n","       device='cuda:0')\n","tensor([  0,   0, 391,   0, 411,   0,   0,   0,   0, 971, 758,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 929,\n","          0, 758, 680,   0], device='cuda:0')\n","tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 5.5694,  0.7285,  1.7559,  ...,  0.1139,  1.1984,  0.6316],\n","        [ 6.4372,  0.7305,  0.0553,  ..., -0.1375, -0.3957,  0.6710],\n","        [ 9.7285,  6.0068,  1.6164,  ...,  0.6610,  3.3989, -0.3627],\n","        ...,\n","        [ 5.4304,  2.6650,  0.5070,  ...,  0.2395,  2.7277, -1.5012],\n","        [ 6.6456,  2.1824, -0.8009,  ...,  0.8781,  2.7999, -1.4318],\n","        [ 5.7667,  1.7440,  0.1930,  ...,  0.4214,  1.9084,  0.8879]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0, 728,   0,   0, 828,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0, 998,   0,   0,   0,   0,\n","          0, 355,   0,   0], device='cuda:0')\n","tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 7.1549,  1.2857, -0.0696,  ...,  0.7808,  1.7178,  1.6543],\n","        [ 6.6628,  2.9871,  2.6179,  ...,  1.7979,  1.3714, -0.1053],\n","        [ 7.3463,  3.4648,  1.9417,  ..., -0.7041,  1.7387,  0.7024],\n","        ...,\n","        [ 7.6519,  2.2489,  0.2929,  ...,  1.6415,  2.9600,  1.5405],\n","        [ 8.7776,  4.3689,  1.0891,  ...,  1.6836,  3.9770, -0.5193],\n","        [ 7.2763,  2.2178, -0.9931,  ...,  0.7185,  3.1646, -0.3554]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0, 643,   0, 562,   0, 472,   0,\n","          0, 239,   0, 902,   0,   0,   0,   0,   0,   0,   0,   0,   0, 626,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 6.5679e+00, -1.2495e-01, -1.1153e+00,  ...,  1.0500e-01,\n","          2.1381e+00, -9.9242e-01],\n","        [ 6.4581e+00,  3.1945e+00,  1.0196e+00,  ...,  7.4138e-01,\n","          1.9905e+00,  3.4711e-01],\n","        [ 1.3113e+01,  4.6410e+00,  5.5082e-01,  ...,  5.4727e+00,\n","          2.9221e+00, -2.0901e+00],\n","        ...,\n","        [ 5.7153e+00,  1.8087e+00,  7.1627e-01,  ..., -7.3197e-01,\n","          1.5709e+00, -4.2384e-01],\n","        [ 7.9106e+00,  1.3190e+00, -5.8865e-02,  ..., -1.1764e+00,\n","         -4.8282e-03, -4.6513e-01],\n","        [ 5.6266e+00,  1.5452e+00,  9.3530e-02,  ...,  6.6540e-01,\n","          6.8027e-01,  8.6438e-02]], device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   1,   0,   0, 463,   0,   0,   0,   0,\n","          0,   0,   0, 987, 837, 719,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 733,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 5.1696,  2.5117, -0.2960,  ...,  0.8657,  2.8221,  2.3260],\n","        [ 6.7602,  2.1377,  0.6516,  ...,  0.0963,  0.9836, -1.1706],\n","        [ 3.1353,  1.8961,  0.1574,  ..., -0.4639,  2.8161, -1.8962],\n","        ...,\n","        [ 7.6746,  2.9310, -0.9572,  ...,  0.6567,  3.2642,  0.0930],\n","        [ 6.1097,  2.0964,  1.5588,  ...,  1.5626,  1.4407, -0.6417],\n","        [ 6.1166,  2.1563,  0.0414,  ...,  1.1620,  8.1002, -0.7892]],\n","       device='cuda:0')\n","tensor([  0,   0, 966,   0,   0,   0,   0, 457, 515, 691,   0,   0,   0,   0,\n","          0,   0,   0, 719,   0,   0, 907,   1, 196,   0,   0,   0,   0,   0,\n","          0,   0,   0, 998], device='cuda:0')\n","tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","tensor([[ 7.4593e+00,  2.0958e+00,  7.5458e-03,  ...,  8.1083e-01,\n","          2.9502e+00,  8.5922e-01],\n","        [ 5.0088e+00,  2.9442e+00,  1.4757e-02,  ...,  1.2227e+00,\n","          4.5113e+00, -1.7237e+00],\n","        [ 8.3950e+00,  3.4924e+00,  7.9814e-01,  ...,  2.0288e+00,\n","          3.2031e+00,  4.3181e-01],\n","        ...,\n","        [ 6.4840e+00,  2.9378e+00,  4.5840e-01,  ...,  2.2733e+00,\n","          1.9870e+00, -4.7198e-01],\n","        [ 8.6688e+00,  4.8247e+00,  2.1964e+00,  ..., -6.4440e-01,\n","          2.0326e+00, -1.6043e-01],\n","        [ 5.7492e+00,  2.3747e+00,  1.0673e+00,  ...,  1.9468e+00,\n","          2.3753e+00,  1.0072e+00]], device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0, 643,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","tensor([[ 6.3569,  2.2399,  0.0445,  ..., -0.7762,  3.4518,  0.9794],\n","        [ 8.3934,  2.5347,  0.7975,  ..., -0.5721,  2.1571,  1.1493],\n","        [ 6.7036,  2.4787,  0.5195,  ..., -0.8505,  2.8281,  0.0748],\n","        ...,\n","        [ 4.1039,  1.0758,  0.5930,  ..., -0.7091,  3.6961,  1.2948],\n","        [ 5.5268,  5.1983,  1.1092,  ..., -0.1639,  2.9268,  1.1173],\n","        [ 6.1634,  1.6004,  0.9037,  ...,  0.3722,  1.1577, -1.1855]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0, 151,   0,   0,   0,   0,\n","          0, 248,   0,   0,   0,   0,   0,   0, 196,   0, 843,   0,   0,   0,\n","          0, 674, 929,   0], device='cuda:0')\n","tensor([2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 6.4700,  2.6988, -0.4060,  ...,  0.7633,  2.2748,  0.2345],\n","        [ 4.1169,  0.1809, -1.2213,  ..., -0.1191,  0.9956,  0.6745],\n","        [ 5.4815,  2.8720,  0.8298,  ...,  1.2113,  1.4086, -0.1506],\n","        ...,\n","        [ 8.4755,  4.7325,  1.1035,  ...,  1.9961,  2.2461, -0.6867],\n","        [ 7.3701,  2.2861,  1.0180,  ..., -0.2957,  2.0681,  2.0932],\n","        [ 5.1996,  1.0303, -0.1865,  ..., -0.6578,  4.5126,  0.1753]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0, 852,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 904,   0,   0,   0,   0,   0,\n","        371,   0,   0,   0], device='cuda:0')\n","tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 8.0364,  4.4117,  1.0842,  ...,  1.5251,  2.6348, -1.0079],\n","        [ 6.3481,  5.0058,  0.6730,  ...,  0.3806,  1.0905, -1.1806],\n","        [ 5.1278,  1.9074,  0.4120,  ..., -0.4633,  1.7762,  0.0471],\n","        ...,\n","        [ 5.5308,  0.2255,  0.3457,  ...,  1.7116,  3.2962,  0.6505],\n","        [ 4.6523,  0.0890, -0.0261,  ..., -1.3018, -0.2472, -0.2561],\n","        [ 4.1674,  2.8974,  0.8464,  ...,  0.2073,  2.5323,  2.3997]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0, 124,   0,   0,   0,   0,\n","          0, 714, 932, 487,   0,   0,   0,   0,   0, 641,   0,   0, 684,   0,\n","          0,   0,   0, 124], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 2, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","tensor([[ 6.7146,  1.6349, -0.2827,  ...,  0.9333,  0.5830,  0.6071],\n","        [ 7.2191,  1.4053,  1.1575,  ..., -1.0526,  1.5460, -1.0882],\n","        [ 3.6752,  1.6505, -0.4940,  ..., -0.5156,  1.0211, -1.2602],\n","        ...,\n","        [ 7.9250,  1.2006,  1.1252,  ...,  0.8079,  2.6973, -0.0577],\n","        [ 8.8809,  3.1156,  0.4198,  ...,  1.3637,  2.5724, -1.7879],\n","        [ 5.9288,  2.5288,  0.7949,  ..., -1.3234,  1.1046,  0.9696]],\n","       device='cuda:0')\n","tensor([  0,   0,   0, 710,   0, 570,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0, 766,   0,   0,   0,   0, 124,   0,   0,   0,   0, 338,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 2, 1, 0, 0], device='cuda:0')\n","tensor([[ 6.5868,  3.5126,  0.4736,  ...,  1.1100,  1.7865,  0.3122],\n","        [ 8.5658,  2.7085,  0.5550,  ...,  0.2385,  2.7530, -2.0947],\n","        [ 6.5624,  3.7476, -0.5838,  ..., -0.4697,  2.1242, -0.6340],\n","        ...,\n","        [ 6.0724,  3.3905,  0.8183,  ..., -0.8867,  0.7185,  0.5169],\n","        [ 7.9527,  1.7398,  0.4581,  ...,  2.6174,  3.0207, -0.4693],\n","        [ 7.5206,  1.6258, -0.4001,  ...,  1.3451,  3.2938, -1.0228]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0, 828,   0,   0, 902,   0,\n","        938,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","tensor([[ 4.8599, -0.0653, -0.2771,  ..., -0.5608,  0.2990,  0.5825],\n","        [ 6.4998,  1.2498,  0.8845,  ..., -0.2590,  0.7528, -0.6507],\n","        [ 6.4099,  1.1675, -1.5225,  ..., -1.3024,  1.9226, -0.0498],\n","        ...,\n","        [ 6.6236,  5.0094,  1.4514,  ...,  1.2617,  3.4803, -1.6516],\n","        [ 6.7248,  1.1426, -0.2523,  ...,  3.6601,  0.2867,  0.8650],\n","        [ 5.4860,  3.5129,  0.3597,  ...,  0.4695,  3.6931, -1.1774]],\n","       device='cuda:0')\n","tensor([835,   0,   0, 987,   0, 987,   0, 696,   0,   0,   0, 904,   0,   0,\n","          0, 740, 850,   0,   0, 987, 332,   0,   0,   0,   0,   0, 676, 898,\n","        861,   0,   0,   0], device='cuda:0')\n","tensor([1, 2, 1, 1, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n","        2, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 8.1867,  4.8963,  1.4824,  ...,  0.4755,  4.8228, -1.2491],\n","        [ 6.1973,  3.9407, -1.5689,  ..., -0.0508,  1.5170,  0.6560],\n","        [ 7.1280,  2.3759,  1.7705,  ...,  0.5923,  1.7590,  0.9426],\n","        ...,\n","        [ 5.1774,  2.4956, -0.1760,  ...,  0.3032,  4.0085,  1.2507],\n","        [ 6.4252,  2.2901,  0.7789,  ..., -1.7962,  0.8669, -0.9091],\n","        [ 4.6530,  2.4560, -0.3906,  ..., -0.3347,  1.6175, -0.0671]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 828,\n","          0,   0,   0, 733,   0,   0, 907,   0,   0,   0, 987,   0,   0,   0,\n","          0,   0,   0, 791], device='cuda:0')\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0,\n","        1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n","tensor([[ 8.1821,  3.8740, -0.0768,  ...,  1.2936,  2.8866,  0.4704],\n","        [ 5.5284,  2.6189,  1.6054,  ..., -0.9413,  1.7721, -0.1536],\n","        [ 7.3274,  1.8169, -0.7528,  ...,  0.9489,  1.8146,  3.1172],\n","        ...,\n","        [ 9.4448,  4.7396,  0.0158,  ...,  2.5330,  2.5339,  0.0322],\n","        [ 9.5312,  1.9426,  0.0400,  ...,  1.4314,  0.4821, -1.1798],\n","        [ 6.6241,  2.2733,  0.6326,  ...,  1.2240,  3.6448, -1.1217]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0, 664,   0,   0, 389,   0,   0,   0, 852,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 807, 714,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 2, 0, 0], device='cuda:0')\n","tensor([[ 6.2873,  2.8389,  0.5923,  ..., -2.1620,  1.3692,  1.3769],\n","        [ 7.2340,  2.0233, -0.6187,  ...,  0.5682,  3.6397,  1.6875],\n","        [ 6.8096,  3.8152,  1.5731,  ...,  1.2357,  2.1511,  0.4392],\n","        ...,\n","        [ 8.5130,  2.5551,  1.6498,  ...,  1.0006,  1.5658, -1.3668],\n","        [ 7.7632,  1.8855,  1.1620,  ...,  0.3356,  1.6596, -0.4142],\n","        [ 9.1159,  2.0181,  0.6950,  ...,  2.3379,  2.5582,  0.7678]],\n","       device='cuda:0')\n","tensor([796,   0,   0,   0,   0, 622,   0,   0, 643,   0,   0, 439,   0,   0,\n","          0,   0,   0,   0,   0, 947,   0,   0, 643,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 1, 2, 1, 1, 0], device='cuda:0')\n","tensor([[ 7.2776,  4.9067,  2.3643,  ...,  0.1023,  3.5996,  0.8458],\n","        [ 7.2797,  2.7907,  0.4674,  ...,  0.8721,  4.3494, -1.0385],\n","        [ 5.9268,  2.1192,  2.9266,  ..., -0.6431, -0.3033, -0.8495],\n","        ...,\n","        [ 7.2355,  2.4497,  0.0729,  ...,  1.4440,  1.4840,  0.2636],\n","        [ 8.2493,  1.7475,  1.6179,  ..., -0.8381,  0.5386,  0.2449],\n","        [ 5.5874,  1.8899,  1.1114,  ...,  1.0763,  1.5861, -2.0313]],\n","       device='cuda:0')\n","tensor([  0,   0, 391,   0,   0,   0,   0,   0,   0, 766,   0,   0,   0,   0,\n","          0,   0, 761, 733,   0,   0,   0,   0,   0,   0, 758,   0,   0,   0,\n","          0,   0, 796,   0], device='cuda:0')\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 5.8607,  3.4344,  0.2180,  ...,  0.6845,  0.9108,  1.6363],\n","        [ 8.7758,  2.1224,  1.7425,  ...,  1.1975,  1.5878, -1.7986],\n","        [ 7.8584,  3.0947,  1.9195,  ...,  0.5492,  4.5622,  2.7137],\n","        ...,\n","        [ 7.0909,  2.4963, -0.1895,  ...,  1.1062,  1.9888,  2.4280],\n","        [ 8.2036,  3.5041,  0.0716,  ...,  1.8906,  1.9081, -0.8135],\n","        [ 6.2133,  4.0043,  0.5285,  ..., -0.1596,  1.0140, -0.4357]],\n","       device='cuda:0')\n","tensor([  0,   0,   0, 741, 250,   0,   0, 154,   0, 469,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0, 176,   0,   0,   0, 113, 987,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 7.7657,  4.7101,  0.5130,  ...,  1.6962,  3.4828,  0.7302],\n","        [ 6.8135,  4.5002,  0.2467,  ...,  1.4790,  1.9711,  1.7797],\n","        [ 6.0749,  1.0956, -0.4912,  ...,  1.1870,  0.7108,  0.7754],\n","        ...,\n","        [ 5.4042,  2.1804, -0.7718,  ...,  0.9579,  2.8072,  0.5841],\n","        [ 7.1940,  4.3888,  0.4251,  ...,  0.3340,  3.4856,  0.7485],\n","        [ 3.8193,  0.8292, -0.7132,  ...,  0.2047,  1.6283,  0.6607]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 758,   0,   0,\n","          0,   0,   0,   0, 475,   0,   0,   0, 796,   0,   0, 207,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n","        0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n","tensor([[ 6.6127,  3.7910,  0.6271,  ...,  1.0484,  1.6889,  0.6726],\n","        [ 3.3866,  1.6101,  2.3469,  ..., -2.4043,  0.3238,  0.9810],\n","        [ 6.9083,  1.3480, -0.4866,  ..., -0.7380,  3.6633,  1.1269],\n","        ...,\n","        [ 8.0834,  4.8773,  0.5028,  ...,  1.4229,  1.9551, -0.6397],\n","        [ 7.4095,  2.9878,  0.3920,  ...,  2.3811,  0.9410, -1.8592],\n","        [ 6.6989,  4.4555,  2.3719,  ..., -0.1522,  1.7101,  0.4876]],\n","       device='cuda:0')\n","tensor([  0, 503,   0, 676,   0, 338,   0, 833, 169,   0, 382,   0,   0,   0,\n","          0, 223,   0,   0,   0,   0, 758,   0,   0,   0,   0,   0,   0,   0,\n","        248,   0,   0,   0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n","        0, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[ 4.6143,  0.8930,  1.0557,  ..., -1.7738, -0.4691,  0.7430],\n","        [ 6.8780,  3.0859,  0.7758,  ...,  0.5461,  2.1958, -0.2541],\n","        [ 5.5423,  3.5280,  1.1273,  ..., -0.0452,  1.8061, -0.2542],\n","        ...,\n","        [ 7.2248,  2.9306,  1.1127,  ..., -0.3211,  1.8935, -0.8888],\n","        [ 5.2849,  1.7195,  1.2372,  ..., -0.3496,  1.0703,  0.7456],\n","        [ 4.6176,  1.7402, -0.2597,  ...,  2.2589,  2.5711, -0.1228]],\n","       device='cuda:0')\n","tensor([  0,   0,   0,   0,   0, 876,   0, 826,   0,   0,  93,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0, 714,   0,   0,   0,   0, 574,   0, 174,\n","          0,   0,   0, 357], device='cuda:0')\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([[10.1148,  2.2660,  1.5944,  ...,  2.3690,  2.0588,  0.2410],\n","        [ 6.0231,  1.1163, -0.1142,  ..., -0.6461,  1.5503, -0.6055],\n","        [ 7.0585,  1.6957,  0.9329,  ...,  0.0941,  1.3656, -0.6554],\n","        ...,\n","        [ 5.1675,  0.5703, -0.3836,  ...,  0.5027,  0.7606,  0.4861],\n","        [ 7.1899,  1.5718,  0.0762,  ...,  0.4991,  0.9470, -0.0852],\n","        [ 6.5487,  1.0663,  1.4557,  ..., -0.1316,  1.5328,  1.3867]],\n","       device='cuda:0')\n","tensor([  0,   0,   0, 234, 967,   0,   0,   0,   0,   0,   0, 876,   0,   0,\n","        679,   0,   0,   0, 391, 921,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0], device='cuda:0')\n","tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n","        2, 2, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","tensor([[ 5.6791,  2.2170, -0.8585,  ..., -1.4303,  1.3405,  0.8397],\n","        [ 8.2169,  4.5481,  0.5268,  ...,  0.7365,  1.2926, -0.2465],\n","        [ 6.3217,  3.2199, -1.2183,  ...,  0.5664,  1.9844,  1.8149],\n","        [ 7.3942,  2.1609,  1.4985,  ...,  2.4082,  2.4285, -0.4911],\n","        [ 8.6285,  3.3113,  0.3199,  ..., -0.8980,  2.8991,  0.7105],\n","        [ 6.2737,  2.0712,  2.9668,  ...,  0.9000,  3.3301,  0.2840]],\n","       device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([0, 0, 0, 0, 0, 0], device='cuda:0')\n","Test Accuracy: 65.22%\n"]}],"source":["# After training, you can evaluate the model on the test set if needed\n","# Example evaluation code:\n","model.eval()  # Set the model to evaluation mode\n","correct = 0\n","total = 0\n","predictions = []\n","with torch.no_grad():\n","    model = model.to(device)\n","    for inputs, labels in test_dataloader:\n","        \n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs)\n","        print(outputs)\n","        _, predicted = torch.max(outputs, 1)\n","        predictions.append(predicted)\n","        print(predicted)\n","        print(labels)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f'Test Accuracy: {100 * accuracy:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<torch.utils.data.dataloader.DataLoader object at 0x000001D68ABF56A0>\n"]}],"source":["print(test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_image(img_tensor, annotation):\n","    \n","    fig,ax = plt.subplots(1)\n","    img = img_tensor.cpu().data\n","\n","    # Display the image\n","    ax.imshow(img.permute(1, 2, 0))\n","    annots = annotation[\"boxes\"].cpu().data\n","    \n","    for box in annots:\n","        xmin, ymin, xmax, ymax = box\n","\n","        # Create a Rectangle patch\n","        rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n","\n","        # Add the patch to the Axes\n","        ax.add_patch(rect)\n","\n","    plt.show()\n","\n","print(\"Prediction\")\n","plot_image(imgs[2], preds[2])\n","print(\"Target\")\n","plot_image(imgs[2], annotations[2])\n","\n","torch.save(model.state_dict(),'model.pt')\n","model2 = get_model_instance_segmentation(3)"]},{"cell_type":"markdown","metadata":{},"source":["# Reference"]},{"cell_type":"markdown","metadata":{},"source":["https://arxiv.org/pdf/1512.03385.pdf\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":667889,"sourceId":1176415,"sourceType":"datasetVersion"}],"dockerImageVersionId":30145,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
